{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7245d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "try:\n",
    "    get_ipython\n",
    "    current_dir = os.getcwd()\n",
    "except NameError:\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Set path，temporary path expansion\n",
    "project_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.vectorstores import  FAISS\n",
    "from langchain_chroma import Chroma\n",
    "from LoadData import load_document,chunk_data\n",
    "\n",
    "from tool import skip_execution\n",
    "IS_SKIP =True\n",
    "embedding_name=\"BAAI/bge-small-zh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0cf54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_emb_model(name):\n",
    "    from huggingface_hub import snapshot_download\n",
    "\n",
    "    # 下载 BAAI 官方的 BGE-Small 中文模型（自带 sentence_bert_config.json）\n",
    "    snapshot_download(\n",
    "        repo_id=name, \n",
    "        local_dir=os.path.join(project_dir,\"model\",name),\n",
    "        local_dir_use_symlinks=False,  # Windows 必加\n",
    "        allow_patterns=[\"*.json\", \"*.bin\", \"*.txt\", \"*.model\"] \n",
    "    )\n",
    "\n",
    "# download_emb_model(embedding_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cf216d",
   "metadata": {},
   "source": [
    "https://huggingface.co/BAAI/bge-small-zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73eb7223",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embedding(embedding_name):\n",
    "    \"\"\"\n",
    "    根据embedding名称加载对应的嵌入模型\n",
    "    \"\"\"\n",
    "    # 通用模型参数配置\n",
    "    model_kwargs = {'device': 'cuda'}  \n",
    "    encode_kwargs = {'normalize_embeddings': True}  # 归一化嵌入向量\n",
    "    \n",
    "    embedding_path = os.path.join(project_dir,\"model\",embedding_name)\n",
    "    print(embedding_path)\n",
    "    \n",
    "    return HuggingFaceEmbeddings(\n",
    "            model_name=embedding_path,\n",
    "            model_kwargs=model_kwargs,\n",
    "            encode_kwargs=encode_kwargs)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aac657",
   "metadata": {},
   "source": [
    "* 闭源 API 模型\t: OpenAIEmbeddings\n",
    "  * OpenAI Ada-002、Anthropic Claude\t\t\n",
    "* 开源本地模型\t: HuggingFaceEmbeddings\n",
    "  * BERT、Sentence-BERT（如 all-MiniLM）\t\t\n",
    "* 云厂商模型\t: AliyunEmbeddings\n",
    "  * 阿里云通义千问嵌入、腾讯云向量嵌入\t "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e838cb8",
   "metadata": {},
   "source": [
    "使用embedding模型持久化存储，目前常用的中文模型是bge-large-zh-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d959520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zzz/RAG_demo/model/BAAI/bge-small-zh\n",
      "嵌入向量维度: 512\n",
      "嵌入向量前5个值: [-0.06145749241113663, 0.00800270028412342, 0.037498682737350464, -0.007267102599143982, -0.03611401841044426]\n"
     ]
    }
   ],
   "source": [
    "@skip_execution(IS_SKIP)\n",
    "def test_emb(): \n",
    "    embedding=get_embedding(embedding_name)\n",
    "          # 测试生成嵌入向量\n",
    "    test_text = \"这是一个测试句子，用于验证嵌入模型是否正常工作。\"\n",
    "    embedding_vector = embedding.embed_query(test_text)\n",
    "        \n",
    "        # 输出结果信息\n",
    "    print(f\"嵌入向量维度: {len(embedding_vector)}\")\n",
    "    print(f\"嵌入向量前5个值: {embedding_vector[:5]}\")\n",
    " \n",
    "    \n",
    "test_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46c687c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings using OpenAIEmbeddings() and save them in a Chroma vector store\n",
    "def create_embeddings_chroma(embedding_name, chunks, persist_dir=os.path.join(project_dir,\"db/chroma_db\")):\n",
    "    \"\"\"\n",
    "    创建并保存 Chroma 向量库\n",
    "    \"\"\"\n",
    "    # 获取嵌入模型\n",
    "    embeddings = get_embedding(embedding_name)\n",
    "    if not os.path.isdir(persist_dir):\n",
    "        os.mkdir(persist_dir)\n",
    "\n",
    "    # 创建向量库时指定保存路径\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_dir  # 指定本地保存目录\n",
    "    )\n",
    "    \n",
    "    # 打印保存信息\n",
    "    print(f\"Chroma 向量库已保存到: {os.path.abspath(persist_dir)}\")\n",
    "    return vector_store\n",
    "\n",
    "def load_embeddings_chroma(embedding_name, persist_dir):\n",
    "    \"\"\"\n",
    "    加载已保存的 Chroma 向量库\n",
    "    \"\"\"\n",
    "    # 获取与创建时相同的嵌入模型（必须一致，否则向量不兼容）\n",
    "    embeddings = get_embedding(embedding_name)\n",
    "    \n",
    "    # 加载本地向量库\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=persist_dir,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    \n",
    "    print(f\"Chroma 向量库已从 {os.path.abspath(persist_dir)} 加载\")\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a937e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/zzz/RAG_demo/datasets/tangshi.pdf\n",
      "352\n",
      "/home/zzz/RAG_demo/model/BAAI/bge-small-zh\n",
      "Chroma 向量库已保存到: /home/zzz/RAG_demo/db/chroma_db\n",
      "/home/zzz/RAG_demo/model/BAAI/bge-small-zh\n",
      "Chroma 向量库已从 /home/zzz/RAG_demo/db/chroma_db 加载\n"
     ]
    }
   ],
   "source": [
    "@skip_execution(IS_SKIP)\n",
    "def test_chroma():\n",
    "    path = os.path.join(project_dir,\"datasets/tangshi.pdf\") \n",
    "    vector_path =os.path.join(project_dir,\"db/chroma_db\") \n",
    "\n",
    "    data = load_document(path)\n",
    "    chunks = chunk_data(data,chunk_size=512,chunk_overlap=100) \n",
    "    print(len(chunks))\n",
    "    create_embeddings_chroma(embedding_name,chunks,vector_path)\n",
    "    load_embeddings_chroma(embedding_name,vector_path)\n",
    "test_chroma()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d09ef",
   "metadata": {},
   "source": [
    "### Faiss\n",
    "Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. \n",
    "\n",
    "https://faiss.ai/\n",
    "\n",
    "https://github.com/facebookresearch/faiss?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2ecb4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_embeddings_faiss( embedding_name, chunks,vector_db_path=os.path.join(project_dir,\"db/faiss_db\") ):\n",
    "    \"\"\"\n",
    "    使用FAISS向量数据库，并保存\n",
    "    \"\"\"\n",
    "    embeddings = get_embedding(embedding_name)\n",
    "    db = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "    if not os.path.isdir(vector_db_path):\n",
    "        os.mkdir(vector_db_path)\n",
    "\n",
    "    db.save_local(folder_path=vector_db_path)\n",
    "    return db\n",
    "\n",
    "\n",
    "def load_embeddings_faiss( embedding_name,vector_db_path):\n",
    "    \"\"\"\n",
    "    加载向量库\n",
    "    \"\"\"\n",
    "    embeddings = get_embedding(embedding_name)\n",
    "    db = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce40412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/zzz/RAG_demo/datasets/tangshi.pdf\n",
      "/home/zzz/RAG_demo/model/BAAI/bge-small-zh\n",
      "/home/zzz/RAG_demo/model/BAAI/bge-small-zh\n"
     ]
    }
   ],
   "source": [
    "@skip_execution(IS_SKIP)\n",
    "def test_faiss():\n",
    "    path = os.path.join(project_dir,\"datasets/tangshi.pdf\") \n",
    "    vector_path =os.path.join(project_dir,\"db/faiss_db\") \n",
    "    data = load_document(path)\n",
    "    chunks = chunk_data(data,chunk_size=512,chunk_overlap=100) \n",
    "    create_embeddings_faiss(embedding_name,chunks,vector_path)\n",
    "    load_embeddings_faiss(embedding_name,vector_path)\n",
    "    \n",
    "test_faiss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
